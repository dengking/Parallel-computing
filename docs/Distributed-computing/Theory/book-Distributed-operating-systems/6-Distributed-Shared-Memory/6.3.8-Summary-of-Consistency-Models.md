[TOC]

# [6.3.8. Summary of Consistency Models](https://www.e-reading.club/chapter.php/143358/224/Tanenbaum_-_Distributed_operating_systems.html)

Although other **consistency models** have been proposed, the main ones are discussed above. They differ in how **restrictive** they are, how complex their implementations are, their ease of programming, and their performance. **Strict consistency** is the most **restrictive**, but because its implementation in a DSM system is essentially impossible, it is never used.  

**Sequential consistency** is feasible, popular with programmers, and widely used. It has the problem of **poor performance**, however. The way to get around this result is to relax the **consistency model**. Some of the possibilities are shown in Fig. 6-24(a), roughly in order of decreasing restrictiveness.  

| Consistency | Description                                                  |
| ----------- | ------------------------------------------------------------ |
| Strict      | Absolute **time ordering** of all **shared accesses** matters |
| Sequential  | All processes see all **shared accesses** in the same order  |
| Causal      | All processes see all casually-related **shared accesses** in the same order |
| Processor   | PRAM consistency + memory coherence                          |
| PRAM        | All processes see writes from each processor in the order they were issued. Writes from different processors may not always be seen in the same order |

(a) 

|         |                                                              |
| ------- | ------------------------------------------------------------ |
| Weak    | **Shared data** can only be counted on to be consistent after a **synchronization** is done |
| Release | **Shared data** are made consistent when a **critical region** is exited |
| Entry   | **Shared data** pertaining to a critical region are made consistent when a **critical region** is entered |

(b)

Fig. 6-24. (a) **Consistency models** not using **synchronization operations**. (b) Models with **synchronization operations**. 

Causal consistency, processor consistency, and PRAM consistency all represent weakenings in which there is no longer a globally agreed upon view of which operations appeared in which order. Different processes may see different sequences of operations. These three differ in terms of which sequences are allowed and which are not, but in all cases, it is up to the programmer to avoid doing things that work only if the memory is sequentially consistent. 

A different approach is to introduce explicit synchronization variables, as weak consistency, release consistency, and entry consistency do. These three are summarized in Fig. 6-24(b). When a process performs an operation on an ordinary shared data variable, no guarantees are given about when they will be visible to other processes. Only when a synchronization variable is accessed are changes propagated. The three models differ in how synchronization works, but in all cases a process can perform multiple reads and writes in a critical section without invoking any data transport. When the critical section has been completed, the final result is either propagated to the other processes or made ready for propagation should anyone else express interest.

In short, weak consistency, release consistency, and entry consistency require additional programming constructs that, when used as directed, allow programmers to pretend that memory is sequentially consistent, when, in fact, it is not. In principle, these three models using explicit synchronization should be able to offer the best performance, but it is likely that different applications will give quite different results. More research is needed before we can draw any firm conclusions here. 